# Handeling Missing Data

## Load libraries

```{r}
library(httr)
library(jsonlite)
library(DBI)
library(RSQLite)
library(ggplot2)
```

## Fetch Data

#### note: run data fetching part only once to make sure. To fetch all the data into database take couple hours

```{r}


# Connect to database
conn <- dbConnect(SQLite(), "anime_full_database.sqlite")

safe_extract <- function(x) {
  if (is.null(x) || length(x) == 0) {
    return(NA)
  } else {
    return(x)
  }
}

insert_anime <- function(data) {
  dbExecute(conn, "
    INSERT OR REPLACE INTO anime_full 
    (mal_id, title, title_english, title_japanese, type, source, episodes, status, airing, aired_from, aired_to, duration, rating, score, scored_by, rank, popularity, members, favorites, synopsis, background, season, year, broadcast_day, broadcast_time, broadcast_timezone, url)
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
  ", params = list(
    safe_extract(data[["mal_id"]]),
    safe_extract(data[["title"]]),
    safe_extract(data[["title_english"]]),
    safe_extract(data[["title_japanese"]]),
    safe_extract(data[["type"]]),
    safe_extract(data[["source"]]),
    safe_extract(data[["episodes"]]),
    safe_extract(data[["status"]]),
    safe_extract(data[["airing"]]),
    safe_extract(data[["aired"]][["from"]]),
    safe_extract(data[["aired"]][["to"]]),
    safe_extract(data[["duration"]]),
    safe_extract(data[["rating"]]),
    safe_extract(data[["score"]]),
    safe_extract(data[["scored_by"]]),
    safe_extract(data[["rank"]]),
    safe_extract(data[["popularity"]]),
    safe_extract(data[["members"]]),
    safe_extract(data[["favorites"]]),
    safe_extract(data[["synopsis"]]),
    safe_extract(data[["background"]]),
    safe_extract(data[["season"]]),
    safe_extract(data[["year"]]),
    safe_extract(data[["broadcast"]][["day"]]),
    safe_extract(data[["broadcast"]][["time"]]),
    safe_extract(data[["broadcast"]][["timezone"]]),
    safe_extract(data[["url"]])
  ))
}


fetch_page_anime <- function(page_num) {
  url <- paste0("https://api.jikan.moe/v4/anime?page=", page_num)
  resp <- GET(url)
  
  if (status_code(resp) == 200) {
    result <- fromJSON(content(resp, "text", encoding = "UTF-8"), simplifyVector = FALSE)
    anime_list <- result$data
    
    for (i in seq_along(anime_list)) {
      insert_anime(anime_list[[i]])
    }
    
    cat("Page", page_num, "done! Inserted", length(anime_list), "animes.\n")
  } else {
    cat("Failed to fetch page", page_num, "Status:", status_code(resp), "\n")
  }
}


# Fetch pages 1 to n
for (page in 1:1000) {
  fetch_page_anime(page)
  Sys.sleep(1) # avoid being rate-limited
}

for (page in 1000:1100) {
  fetch_page_anime(page)
  Sys.sleep(1) 
}

for (page in 1100:1150) {
  fetch_page_anime(page)
  Sys.sleep(1)
}



```

## Attach genre to the database

```{r}
dbExecute(conn, "ALTER TABLE anime_full ADD COLUMN genres TEXT;")

```

### create function for fetch anime genres

```{r}
library(httr)
library(jsonlite)

fetch_anime_genres <- function(mal_id) {
  url <- paste0("https://api.jikan.moe/v4/anime/", mal_id)
  resp <- GET(url)
  
  if (status_code(resp) == 200) {
    data <- fromJSON(content(resp, "text", encoding = "UTF-8"))$data
    genres_list <- data$genres
    if (length(genres_list) == 0) {
      return(NA)
    } else {
      return(paste(genres_list$name, collapse = ", "))
    }
  } else {
    return(NA)
  }
}

```

### fetch genres

```{r}
# instead of get all mal_id, getting mal_id with whose genre is null is more efficient, and can also query multiple time if a computer is not avaliable right now.
mal_ids <- dbGetQuery(conn, "SELECT mal_id FROM anime_full WHERE genres IS NULL ")$mal_id

for (i in seq_along(mal_ids)) {
  id <- mal_ids[i]
  genres <- fetch_anime_genres(id)
  
  # Update the database
  dbExecute(conn, "UPDATE anime_full SET genres = ? WHERE mal_id = ?", params = list(genres, id))
  
  cat("Updated mal_id:", id, "Genres:", genres, "\n")
  
  Sys.sleep(0.9) # Sleep to avoid hitting API rate limit

}

mal_ids <- mal_ids[720:length(mal_ids)]
mal_ids[1]
# Find the index where mal_id == 17563
start_index <- which(mal_ids == 30845)

# Loop from start_index to the end
for (i in start_index:length(mal_ids)) {
  id <- mal_ids[i]
  genres <- fetch_anime_genres(id)
  
  # Update the database
  dbExecute(conn, "UPDATE anime_full SET genres = ? WHERE mal_id = ?", params = list(genres, id))
  
  cat("Updated mal_id:", id, "Genres:", genres, "\n")
  
  Sys.sleep(0.7) # Sleep to avoid API rate limit
}

# for test
dbGetQuery(conn, "SELECT mal_id, genres, producers, studios FROM anime_full")
```

### Add studios and producers into database

```{r}
dbExecute(conn, "ALTER TABLE anime_full ADD COLUMN producers TEXT;")
dbExecute(conn, "ALTER TABLE anime_full ADD COLUMN studios TEXT;")

```

### Create a callable function for fetching producers and studios

```{r}
library(httr)
library(jsonlite)

fetch_producers_studios <- function(mal_id) {
  url <- paste0("https://api.jikan.moe/v4/anime/", mal_id, "/full")
  resp <- GET(url)
  
  if (status_code(resp) == 200) {
    data <- fromJSON(content(resp, "text", encoding = "UTF-8"), simplifyDataFrame = FALSE)$data
    
    producers <- if (length(data$producers) > 0) {
      paste(sapply(data$producers, function(x) x$name), collapse = ", ")
    } else {
      NA
    }
    
    studios <- if (length(data$studios) > 0) {
      paste(sapply(data$studios, function(x) x$name), collapse = ", ")
    } else {
      NA
    }
    
    return(list(producers = producers, studios = studios))
  } else {
    cat("Failed to fetch", mal_id, "Status:", status_code(resp), "\n")
    return(list(producers = NA, studios = NA))
  }
}

mal_ids <- dbGetQuery(conn, "SELECT mal_id FROM anime_full WHERE producers IS NULL OR studios IS NULL")$mal_id
```

### Fetch producers and studios

```{r}

mal_ids[10000]
# Find the index where mal_id == 17563
conn <- dbConnect(SQLite(), "anime_full_database.sqlite")

start_index <- which(mal_ids == 61578)

# Loop from start_index to the end
for (i in start_index:length(mal_ids)) {
  id <- mal_ids[i]
  info <- fetch_producers_studios(id)
  
  dbExecute(conn,
    "UPDATE anime_full SET producers = ?, studios = ? WHERE mal_id = ?",
    params = list(info$producers, info$studios, id)
  )
  
  cat("Updated mal_id:", id, "\n")
  Sys.sleep(0.9)  # Be polite to the API
}
# instruction for fecthing from middle mal_id refer to 259 to 263 line
# 377 now
```

## Test if data are avaliable

```{r}

dbGetQuery(conn, "SELECT * FROM anime_full")
dbGetQuery(conn, "SELECT COUNT(*) FROM anime_full")
dbGetQuery(conn, "SELECT * FROM anime_full ORDER BY mal_id DESC LIMIT 25")
```

```{r}
# Disconnect after everything done
dbDisconnect(conn)
```

# Check NAs

### Create "check missing" function

```{r}

check_missing <- function(thedata) {
  # Total number of rows
  n_rows <- nrow(thedata)
  
  # Find missing percentage for each column
  missing_summary <- sapply(thedata, function(x) sum(is.na(x)) / n_rows * 100)
  
  # Turn into a nice data frame
  missing_df <- data.frame(
    column = names(missing_summary),
    missing_percent = round(missing_summary, 2)  # Round to 2 decimal places
  )
  
  # Sort by missing_percent descending
  missing_df <- missing_df[order(-missing_df$missing_percent), ]
  
  print(missing_df)
  
  # Missing value graph for the report
  ggplot(missing_df, aes(x = reorder(column, missing_percent), y = missing_percent, fill = -missing_percent)) +
      geom_bar(stat = "identity") +
      geom_text(aes(label = paste0(round(missing_percent, 1), "%")), 
                hjust = -0.1,  # Move the label a little to the right of bar
                size = 4) +    # Text size
      coord_flip() +
      labs(x = "Attribute", y = "Missing Data (%)", title = "Percent Missing of each Attribute in Jikan Anime Data", fill = "Missing Percent" ) +
      theme_minimal() +
      theme(plot.title = element_text(hjust = 0.5, size = 28, face = "bold"),
            axis.title.x = element_text(size = 19),
            axis.title.y = element_text(size = 19),
            axis.text.y = element_text(size = 14),)
  
}


```

### check current raw dataset

```{r}
# Connect if not already
conn <- dbConnect(SQLite(), "anime_full_database.sqlite")

# Read the table
anime_data0 <- dbReadTable(conn, "anime_full")

check_missing(anime_data0)


```

When title is missing, the entire row is invalid, we remove rows with title missing

```{r}

# Keep only rows where title is NOT missing
anime_data1 <- anime_data0[!is.na(anime_data0$title), ]
sum(is.na(anime_data1$title))
nrow(anime_data1)

```

The valid anime rows is now 28318 instead of 28477. Inspect missing values again:

```{r}
check_missing(anime_data1)
```

# Clean Data for Predictive Analysis

#### we remove rows that don't have genre appear

#### we remove rows that don't have producers

#### we remove rows that don't have studios

and check missing data again

```{r}
anime_data2 <- anime_data1[!is.na(anime_data1$genres),]
nrow(anime_data2)
check_missing(anime_data2)
anime_data3 <- anime_data2[!is.na(anime_data2$producers),]
anime_data4 <- anime_data3[!is.na(anime_data3$studios),]
check_missing(anime_data4)

```

#### Then, we select only the attributes we want

```{r}
selected_attributes <- c("mal_id", "title", "type", "episodes", "status", 
                          "rating", "score", "scored_by", "rank", "popularity", 
                          "members", "favorites", "genres", "studios", "producers")
anime_data5 <- anime_data4[, selected_attributes]
check_missing(anime_data5)
```

#### Studios data processing

The data analysis for studios is in data_analysis.Rmd. We want to include the studios column when training the predictive model. Since the column has too many unique values, doint the one-hot encoding will result in a very high dimension of our dataset. We have considered to choose the top10 studios with higest 10 average score, but the output result shows studios with only 1 to 3 anime counts, which does not represent the studios' performance enough.

Based on the analysis, some of the well-known/popular studios usually have a high count of anime with along with a high score. Therefore, we decide to choose studios that have anime count \>= 30 with a score \>= 7.03 (the top 25% of the score). \##### find anime count for each studios

```{r}
studios_stats <- anime_data5 |>
  group_by(studios) |>
  summarise(
    count = n(),
    avg_score = mean(score, na.rm = TRUE),
    .groups = "drop"
  )


```

##### Filter studios with count \>= 30 and score \>= 7.03

The output tibble show the studios that satisfy with our criteria. The output makes sense because these studios below are all well-know studios that produce popular anime each season.

```{r}
top_studios <- studios_stats |>
  filter(count >= 30, avg_score >= 7.03)
top_studios
```

##### Add, Delete column for studios

22 studios were selected. However, 22 is still to much for one-hot encoding. As the result, we decide to further manipulate the column by adding a new column with the following description: For each row, if the studio belongs to 1 of the 22 top studios, we classify it as "top" Otherwise, it is "other".

```{r}
# list of top studios
top22_studios <-  top_studios$studios
# create a copy of anime data
anime_data6 <-anime_data5
anime_data6$studio_rank <- ifelse(
  anime_data6$studios %in% top22_studios,
  "Top",
  "Other"
)
anime_data6$studio_rank <- factor(anime_data6$studio_rank, levels = c("Top", "Other"))

# delete studios column
anime_data6 <- anime_data6 |> select(-studios)

```

Examine the dataset:

```{r}
anime_data6
boxplot(score ~ studio_rank,
        data = anime_data6,
        main = "Score Distribution: Top vs Other Studios",
        xlab = "Studio Rank",
        ylab = "Anime Score",
        col = c("lightblue", "lightgreen"))
summary(anime_data6)
```

##### Producers

The producers show a similar pattern after we splid the multi producer into individual producer. We implement the same thing for producer. \###### Split to individuals

```{r}
producer_long <- anime_data6 |>
  mutate(producer = str_split(producers, ",\\s*")) |>
  unnest(producer)

```

###### Count the average score for each producer

```{r}
producer_stats <- producer_long |>
  group_by(producer) |>
  summarise(
    count = n(),
    avg_score = mean(score, na.rm = TRUE),
    .groups = "drop"
  )

```

###### Filter the top producers

```{r}
top_producers <- producer_stats |>
  filter(count >= 30, avg_score >= 7.03) |>
  arrange(desc(avg_score))

print(top_producers)
```

###### Add column to classify producer as "top" or "other"

```{r}

top_producer_list <- top_producers$producer

tag_producer_rank <- function(producer_string) {
  if (is.na(producer_string)) return("Other")
  individual_producers <- str_split(producer_string, ",\\s*")[[1]]
  if (any(individual_producers %in% top_producer_list)) {
    return("Top")
  }
  return("Other")
}

anime_data6$producer_rank <- sapply(anime_data6$producers, tag_producer_rank)

anime_data6$producer_rank <- factor(anime_data6$producer_rank, levels = c("Top", "Other"))
# delete producers column
anime_data6 <- anime_data6 |> select(-producers)
```

###### Examin new dataset

```{r}
anime_data6
boxplot(score ~ studio_rank,
        data = anime_data6,
        main = "Score Distribution: Top vs Other Producers",
        xlab = "Producer Rank",
        ylab = "Anime Score",
        col = c("lightblue", "lightgreen"))
summary(anime_data6)
```

#### Type Data Processing

```{r}
anime_data7 <- anime_data6
anime_data7$type_rank <- case_when(
  anime_data7$type %in% c("Movie", "TV") ~ "High",
  anime_data7$type %in% c("TV Special", "Special", "ONA") ~ "Mid",
  anime_data7$type %in% c("OVA", "Music", "CM", "PV") ~ "Low",
  TRUE ~ "Other"
)

anime_data7$type_rank <- factor(anime_data7$type_rank, levels = c("Low", "Mid", "High"))

```

##### Examing the new dataset

```{r}
anime_data7
boxplot(score ~ type_rank,
        data = anime_data7,
        main = "Score Distribution: Rank of Types",
        xlab = "Type Rank",
        ylab = "Anime Score",
        col = c("lightblue", "lightgreen","orange"))
anime_data7 <- anime_data7 |> select(-type)
summary(anime_data7)
```

#### Rating Processing

```{r}
anime_data8 <- anime_data7
anime_data8$rating_rank <- case_when(
  anime_data8$rating %in% c("R - 17+ (violence & profanity)", "PG-13 - Teens 13 or older") ~ "High",
  anime_data8$rating %in% c("PG - Children", "G - All Ages", "R+ - Mild Nudity") ~ "Mid",
  anime_data8$rating == "Rx - Hentai" ~ "Low",
  TRUE ~ NA_character_
)

anime_data8$rating_rank <- factor(anime_data8$rating_rank, levels = c("Low", "Mid", "High"))

anime_data8 <- anime_data8 |> select(-rating)
```

##### Examing the new dataset

```{r}
anime_data8
boxplot(score ~ rating_rank,
        data = anime_data8,
        main = "Score Distribution: Rank of Ratings",
        xlab = "Rating Rank",
        ylab = "Anime Score",
        col = c("lightblue", "lightgreen","orange"))
summary(anime_data8)
```

#### Last data processing for predictive analysis

anime_data9 will be the data we use for predictive anlyasis

```{r}
anime_data9 <- anime_data8
anime_data9 <- anime_data9 |> select(-mal_id)
anime_data9 <- anime_data9 |> select(-title)
anime_data9$status <- as.factor(anime_data9$status)
anime_data9
```

### Last

Use the dataset you want for each analysis section:\\

-   anime_data0 = raw data from Jikan API

-   anime_data1 = anime data with no empty title

-   anime_data2 = anime data with no empty title and no empty genres

-   anime_data5 = anime data with no empty title, no empty genres, no empty producers, no empty studios, and reduced columns.

### Improvement if have time

instead of make a copy of each cleaned dataset, an efficient way can be implemented to make it save more storage space

For studios, a manual clean can be implemented since some of the studios with 1-3 anime counts are basically a sub-department from a large studio. We would need to change their categorical value into the name of their large studio. Some other studios with 1-3 anime counts are because the collboration of couple studios together.

### Free block: test/see the data frame here

Type the name of data frame to see the who dataset Type the str(name of dataframe to see the structure of it)

```{r}
anime_data5
str(anime_data5)
```

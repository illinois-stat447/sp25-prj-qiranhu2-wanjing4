# Predictive Analysis

### Importing Necessary Libraries

```{r}
# load library here
library(DBI)
library(RSQLite)
library(dplyr)
library(caret)
library(randomForest)
```

### **Loading the Dataset**

Load the cleaned data from NA_processing Rmd. Call this function whenver we need this version of dataset

```{r}
p_data <- anime_data9
summary(p_data)
```

### Data Preprocessing for predictive analysis
Before implement Predictive Model, we do one hot encoding for top10 genres

```{r}
# One-hot encode only for the top genres
onehot_top10 <- p_data |>
  mutate(row_id = row_number(),
         genres = str_split(genres, ",\\s*")) |>
  unnest(genres) |>
  filter(genres %in% top10_genre) |>
  mutate(dummy = 1) |>
  pivot_wider(
    id_cols = row_id,
    names_from = genres,
    values_from = dummy,
    values_fill = list(dummy = 0)
  )

# Join back to original data
data_1hot <- p_data |>
  mutate(row_id = row_number()) |>
  left_join(onehot_top10, by = "row_id") |>
  select(-row_id)
# we delete the original genres column
data_1hot <- data_1hot |> select(-genres)
summary(data_1hot)
```
## Randomly split into training and testing set
```{r}
# set seed to make sure the same result can be generate again
set.seed(123)
data_1hot <- na.omit(data_1hot)
train_index <- sample(seq_len(nrow(data_1hot)), size = 0.5 * nrow(data_1hot))

train_data <- data_1hot[train_index, ]
test_data <- data_1hot[-train_index, ]

```

Use cross-validation to split training and validation set for better performance.

```{r}
# 10 fold
train_control <- trainControl(method = "cv", number = 10)
```

## Linear Regression Predictive Analysis
### Model Fitting

```{r}
model_lm <- train(score ~ .,
                  data = train_data,
                  method = "lm",
                  trControl = train_control)  
summary(model_lm)
```

### Check the model performance using training set
```{r}
lm_train_predictions <- predict(model_lm, newdata = train_data)
# Evaluate the performance
rmse_lm_train <- RMSE(lm_train_predictions, train_data$score)
r2_lm_train <- R2(lm_train_predictions, train_data$score)

cat("RMSE:", rmse_lm_train, "\n")
cat("R-squared:", r2_lm_train, "\n")

```
#### plot the training performance
```{r}
plot(train_data$score, lm_train_predictions,
     xlab = "Actual Score", ylab = "Predicted Score",
     main = "Predicted vs Actual Scores of \nLinear Regression Predictive Model (Train)",
     col = "steelblue", pch = 19, cex.main = 2.0, cex.lab = 1.5)
abline(a = 0, b = 1, col = "red")

# Add RMSE and R² to the top-left corner
text(x = min(train_data$score), 
     y = max(lm_train_predictions), 
     labels = paste0("RMSE = ", round(rmse_lm_train, 3), 
                     "\nR² = ", round(r2_lm_train, 3)),
     adj = c(0, 1),   # Left-top alignment
     cex = 1.0)       # Text size
```

### Prediction using Testing Set
predict the score of test data and check the performance
```{r}

lm_test_predictions <- predict(model_lm, newdata = test_data)
# Evaluate the performance
rmse_lm_test <- RMSE(lm_test_predictions, test_data$score)
r2_lm_test <- R2(lm_test_predictions, test_data$score)

cat("RMSE:", rmse, "\n")
cat("R-squared:", r2, "\n")
```
### plot the result
```{r}
plot(test_data$score, predictions,
     xlab = "Actual Score", ylab = "Predicted Score",
     main = "Predicted vs Actual Scores of \nLinear Regression Predictive Model",
     col = "steelblue", pch = 19, cex.main = 2.0, cex.lab = 1.5)
abline(a = 0, b = 1, col = "red")

# Add RMSE and R² to the top-left corner
text(x = min(test_data$score), 
     y = max(predictions), 
     labels = paste0("RMSE = ", round(rmse_lm_test, 3), 
                     "\nR² = ", round(r2_lm_test, 3)),
     adj = c(0, 1),   # Left-top alignment
     cex = 1.0)       # Text size

```


## Random Forest Predictive Analysis
### Model Fitting
```{r}
model_rf <- train(
  score ~ ., 
  data = train_data,
  method = "rf",
  ntree = 10,
  trControl = train_control,
  importance = TRUE
)
```
### Check the model performance using training set
```{r}
rf_train_predictions <- predict(model_rf, newdata = train_data)
# Calculate RMSE and R-squared
rmse_rf_train <- RMSE(rf_train_predictions, train_data$score)
r2_rf_train <- R2(rf_train_predictions, train_data$score)

cat("RMSE:", rmse_rf_train, "\n")
cat("R-squared:", r2_rf_train, "\n")

```
### Plot the result
```{r}
plot(train_data$score, rf_train_predictions,
     xlab = "Actual Score", ylab = "Predicted Score",
     main = "Predicted vs Actual Scores of \nRandom Forest Predictive Model(Train)",
     col = "steelblue", pch = 19, cex.main = 2.0, cex.lab = 1.5)
abline(a = 0, b = 1, col = "red")

# Add RMSE and R² to the top-left corner
text(x = min(train_data$score), 
     y = max(rf_train_predictions), 
     labels = paste0("RMSE = ", round(rmse_rf_train, 3), 
                     "\nR² = ", round(r2_rf_train, 3)),
     adj = c(0, 1),   # Left-top alignment
     cex = 1.0)       # Text size
```



### Prediction using Testing Set
```{r}
rf_test_predictions <- predict(model_rf, newdata = test_data)
# Calculate RMSE and R-squared
rmse_rf_test <- RMSE(rf_test_predictions, test_data$score)
r2_rf_test <- R2(rf_test_predictions, test_data$score)

cat("RMSE:", rmse_rf_test, "\n")
cat("R-squared:", r2_rf_test, "\n")

```
### Plot the result
```{r}
plot(test_data$score, rf_test_predictions,
     xlab = "Actual Score", ylab = "Predicted Score",
     main = "Predicted vs Actual Scores of \nRandom Forest Predictive Model",
     col = "steelblue", pch = 19, cex.main = 2.0, cex.lab = 1.5)
abline(a = 0, b = 1, col = "red")

# Add RMSE and R² to the top-left corner
text(x = min(test_data$score), 
     y = max(rf_test_predictions), 
     labels = paste0("RMSE = ", round(rmse_rf_test, 3), 
                     "\nR² = ", round(r2_rf_test, 3)),
     adj = c(0, 1),   # Left-top alignment
     cex = 1.0)       # Text size

```

